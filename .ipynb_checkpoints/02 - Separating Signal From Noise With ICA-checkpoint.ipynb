{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pleasant-concern",
   "metadata": {},
   "source": [
    "# Loading data\n",
    "Ok, let’s load a subject and run an ICA to explore signals that are present. Since we have completed preprocessing, our data should be realigned and also normalized to MNI stereotactic space. We will use the nltools package to work with this data in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "earned-average",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltools.data import Brain_Data\n",
    "from nltools.plotting import component_viewer\n",
    "\n",
    "base_dir = './Localizer/derivatives/fmriprep'\n",
    "sub = 'S01'\n",
    "\n",
    "data = Brain_Data(os.path.join(base_dir, f'sub-{sub}','func', f'sub-{sub}_task-localizer_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-permission",
   "metadata": {},
   "source": [
    "# More Preprocessing\n",
    "Even though, we have technically already run most of the preprocessing there are a couple of more steps that will help make the ICA cleaner.\n",
    "\n",
    "First, we will run a high pass filter to remove any low frequency scanner drift. We will pick a fairly arbitrary filter size of 0.0078hz (1/128s). We will also run spatial smoothing with a 6mm FWHM gaussian kernel to increase a signal to noise ratio at each voxel. These steps are very easy to run using nltools after the data has been loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "simplified-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.filter(sampling_freq=1/2.4, high_pass=1/128)\n",
    "\n",
    "data = data.smooth(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "thousand-congo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltools.data.brain_data.Brain_Data(data=(128, 238955), Y=0, X=(0, 0), mask=MNI152_T1_2mm_brain_mask.nii.gz, output_file=[])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-chapter",
   "metadata": {},
   "source": [
    "# Independent Component Analysis (ICA)\n",
    "Ok, we are finally ready to run an ICA analysis on our data.\n",
    "\n",
    "ICA attempts to perform blind source separation by decomposing a multivariate signal into additive subcomponents that are maximally independent.\n",
    "\n",
    "We will be using the `decompose()` method on our Brain_Data instance. This runs the FastICA algorithm implemented by scikit-learn. You can choose whether you want to run spatial ICA by setting `axis='voxels'` or temporal ICA by setting `axis='images'`. We also recommend running the whitening flat `whiten=True`. By default decompose will estimate the maximum components that are possible given the data. We recommend using a completely arbitrary heuristic of 20-30 components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "civil-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = 2.4\n",
    "output = data.decompose(algorithm='ica', n_components=30, axis='images', whiten=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-acrylic",
   "metadata": {},
   "source": [
    "# Viewing Components\n",
    "We will use the interactive `component_viewer` from nltools to explore the results of the analysis. This viewer uses ipywidgets to select the `Component` to view and also the threshold. You can manually enter a component number to view or scroll up and down.\n",
    "\n",
    "Components have been standardized, this allows us to threshold the brain in terms of standard deviations. For example, the default threshold of 2.0, means that any voxel that loads on the component greater or less than 2 standard deviations will be overlaid on the standard brain. You can play with different thresholds to be more or less inclusive - a threshold of 0 will overlay all of the voxels. If you play with any of the numbers, make sure you press tab to update the plot.\n",
    "\n",
    "The second plot is the time course of the voxels that load on the component. The x-axis is in TRs, which for this dataset is 2.4 sec.\n",
    "\n",
    "The third plot is the powerspectrum of the timecourse. There is not a large range of possible values as we can only observe signals at the nyquist frequency, which is half of our sampling frequency of 1/2.4s (approximately 0.21hz) to a lower bound of 0.0078hz based on our high pass filter. There might be systematic oscillatory signals. Remember, that signals that oscillate a faster frequency than the nyquist frequency will be aliased. This includes physiological artifacts such as respiration and cardiac signals.\n",
    "\n",
    "It is important to note that ICA cannot resolve the sign of the component. So make sure you consider signals that are positive as well as negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deluxe-partnership",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072187dcca0e40849cebb9866683fbdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(BoundedIntText(value=0, description='Component', max=29), BoundedFloatText(value=2.0, de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltools.plotting import component_viewer\n",
    "component_viewer(output, tr=2.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-service",
   "metadata": {},
   "source": [
    "### Artifacts Guesses\n",
    "Exercise **guesses** starting from **0/30**:\n",
    "\n",
    "    Component 4/30: Coverage  \n",
    "    Component 6/30: Cardiac noise  \n",
    "    Component 9/30: Scanner spike  \n",
    "    Component 10/30: Task-correlated head movement  \n",
    "    Component 11/30: Task-correlated head movement  \n",
    "    Component 19/30: Task-correlated head movement  \n",
    "    Component 20/30: Scanner spike  \n",
    "    Component 23/30: Scanner spike  \n",
    "    Component 27/30: Breathing + Scanner spike"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-restaurant",
   "metadata": {},
   "source": [
    "## S-02 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "electric-thumb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a9d7a3db7b41f3afa49c6799b84a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(BoundedIntText(value=0, description='Component', max=29), BoundedFloatText(value=2.0, de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading data\n",
    "sub = 'S02'\n",
    "data = Brain_Data(os.path.join(base_dir, f'sub-{sub}','func', f'sub-{sub}_task-localizer_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'))\n",
    "\n",
    "# Processing\n",
    "data = data.filter(sampling_freq=1/2.4, high_pass=1/128)\n",
    "data = data.smooth(6)\n",
    "\n",
    "# ICA\n",
    "output = data.decompose(algorithm='ica', n_components=30, axis='images', whiten=True)\n",
    "\n",
    "# Display\n",
    "component_viewer(output, tr=2.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-jurisdiction",
   "metadata": {},
   "source": [
    "### Artifacts Guesses\n",
    "Exercise **guesses** starting from **0/30**:\n",
    "\n",
    "    Component 1/30: Breathing\n",
    "    Component 5/30: Scanner spike\n",
    "    Component 6/30: Scanner spike  \n",
    "    Component 9/30: Scanner spike\n",
    "    Component 13/30: Cardiac\n",
    "    Component 14/30: Task-correlated head movement  \n",
    "    Component 22/30: Cardiac\n",
    "    Component 23/30: Scanner spike  \n",
    "    Component 25/30: Scanner spike\n",
    "    Component 26/30: Scanner spike\n",
    "    Component 27/30: Task-correlated head movement  \n",
    "    Component 28/30: Breathing\n",
    "   \n",
    "### Exercises\n",
    "**What features do you think are important to consider when making this judgment?**  \n",
    "Each map/graph seems important for each artifact, therefore I believe it's nice to focus your attention already knowing what you should expect from them (check below answers).\n",
    "\n",
    "**Does the spatial map provide any useful information?**  \n",
    "Yes. As Tor Wager mentioned in [`Principles of fMRI Part 1, Module 9: fMRI Artifacts and Noise`](https://youtu.be/7Kk_RsGycHs?t=350), Task-correlated head movement can be described when the Ventricular system of the brain seems to show activity, which is not phisiologically plausible.\n",
    "\n",
    "**What about the timecourse of the component? Does it map on to the plausible timecourse of the task.**  \n",
    "The `'Intensity (AU)' over 'Timecourse'` component seems important to find Breathing and Cardiac noises, as they provide information **over > time <**, which seems considerably useful, since heartbeating and respiration does not occur in a single instant.\n",
    "\n",
    "**What about the power spectrum?**  \n",
    "Similarly, we can correlate `'Power' over 'Frequency (Hz)'` among issues with the device. This one is probably the answer you should look for when trying to find Scanner spikes artifacts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
